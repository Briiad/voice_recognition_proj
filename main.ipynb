{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "import serial\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from micromlgen import port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"mini_speech_commands\"\n",
    "SAMPLE_RATE = 22050\n",
    "JSON_PATH = \"data.json\"\n",
    "FRAMES = []\n",
    "SHORT_NORMALIZE = (1.0/32768.0)\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "DURATION = 2\n",
    "RATE = 44100\n",
    "TEMPORARY_FILE = \"temp.wav\"\n",
    "SAMPLES_PER_SEGMENT = SAMPLE_RATE * DURATION\n",
    "EXPECTED_MFCC_VECTOR_COUNT = 13\n",
    "MAPPING = [ \"down\", \"stop\", \"up\"]\n",
    "FRAMES_PER_BUFFER = 1024\n",
    "\n",
    "\n",
    "mic = sr.Microphone(device_index=0)\n",
    "rec = sr.Recognizer()\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 'mini_speech_commands\\down'\n",
      "\n",
      "Processing: 'mini_speech_commands\\stop'\n",
      "\n",
      "Processing: 'mini_speech_commands\\up'\n",
      "Finished processing.\n"
     ]
    }
   ],
   "source": [
    "# preprocess data\n",
    "def preprocess_dataset(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512):\n",
    "  \n",
    "      # dictionary to store data\n",
    "      data = {\n",
    "          \"mapping\": [],\n",
    "          \"labels\": [],\n",
    "          \"mfcc\": [],\n",
    "          \"files\": []\n",
    "      }\n",
    "  \n",
    "      # loop through all sub-dirs\n",
    "      for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "  \n",
    "          # ensure we're not at root level\n",
    "          if dirpath is not dataset_path:\n",
    "  \n",
    "              # save label (i.e., sub-dir name) in the mapping\n",
    "              dirpath_components = dirpath.split(\"/\") # \"mini_speech_commands/down\" => [\"mini_speech_commands\", \"down\"]\n",
    "              semantic_label = dirpath_components[-1]\n",
    "              data[\"mapping\"].append(semantic_label)\n",
    "              print(\"\\nProcessing: '{}'\".format(semantic_label))\n",
    "  \n",
    "              # process files for a specific sub-dir\n",
    "              for f in filenames:\n",
    "  \n",
    "                  # load audio file\n",
    "                  file_path = os.path.join(dirpath, f)\n",
    "                  signal, sample_rate = librosa.load(file_path)\n",
    "\n",
    "                  if len(signal) >= SAMPLE_RATE: # ensure consistency of the length of the signal\n",
    "                    signal = signal[:SAMPLE_RATE]\n",
    "  \n",
    "                    # extract MFCCs\n",
    "                    mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "  \n",
    "                    # store data for analysed track\n",
    "                    data[\"mfcc\"].append(mfcc.tolist())\n",
    "                    data[\"labels\"].append(i-1)\n",
    "                    data[\"files\"].append(file_path)\n",
    "                    # print(\"{}: {}\".format(file_path, i-1))\n",
    "  \n",
    "      # save MFCCs to json file\n",
    "      with open(json_path, \"w\") as fp:\n",
    "          json.dump(data, fp, indent=4)\n",
    "  \n",
    "      print(\"Finished processing.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  preprocess_dataset(DATASET_PATH, JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "  \n",
    "    # convert lists into numpy arrays\n",
    "    inputs = np.array(data[\"mfcc\"])\n",
    "    targets = np.array(data[\"labels\"])\n",
    "  \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data using scikit learn\n",
    "def train_test_model(dataset_path):\n",
    "    # load data\n",
    "    X, y = load_data(dataset_path)\n",
    "  \n",
    "    # create train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, validation_split=0.2)\n",
    "\n",
    "    # create network with linear regression\n",
    "    model = LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        multi_class='multinomial',\n",
    "        max_iter=100,\n",
    "        fit_intercept=True,\n",
    "        n_jobs=3,\n",
    "        C=0.1,\n",
    "        class_weight=None,\n",
    "        intercept_scaling=1,\n",
    "        penalty='l2',\n",
    "        random_state=None,\n",
    "        tol=0.0001,\n",
    "        verbose=0,\n",
    "        warm_start=False\n",
    "    )\n",
    "    # model = MLPClassifier(\n",
    "    #     hidden_layer_sizes=(512, 256),\n",
    "    #     activation=\"relu\",\n",
    "    #     solver=\"adam\",\n",
    "    #     batch_size=32,\n",
    "    #     verbose=1,\n",
    "    #     epsilon=1e-8,\n",
    "    #     alpha=0.0001,\n",
    "    #     learning_rate=\"adaptive\",\n",
    "    #     max_iter=100\n",
    "    # )\n",
    "\n",
    "    # reshape the 3d array to 2d array\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "    \n",
    "    # Print some details\n",
    "    print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "    print(\"X_test.shape: {}\".format(X_test.shape))\n",
    "    print(\"y_train.shape: {}\".format(y_train.shape))\n",
    "    print(\"y_test.shape: {}\".format(y_test.shape))\n",
    "\n",
    "    # train network\n",
    "    # model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train, y_train)\n",
    "  \n",
    "    # evaluate network\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "    # save the model using pickle\n",
    "    pickle.dump(model, open(\"model.sav\", 'wb'))\n",
    "\n",
    "    #save the model using json format\n",
    "    model_param = {}\n",
    "    model_param[\"coef_\"] = model.coef_.tolist()\n",
    "    model_param[\"intercept_\"] = model.intercept_.tolist()\n",
    "\n",
    "    json_txt = json.dumps(model_param, indent=4)\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(json_txt)\n",
    "    \n",
    "    # export to plain C\n",
    "    c_code = port(model, instance_name=\"MLClassifier\")\n",
    "\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "    \n",
    "    # print(c_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "X_train.shape: (1877, 572)\n",
      "X_test.shape: (805, 572)\n",
      "y_train.shape: (1877,)\n",
      "y_test.shape: (805,)\n",
      "Accuracy: 74.78%\n"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "if __name__ == \"__main__\":\n",
    "  print(\"Training model...\")\n",
    "  train_test_model(JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording audio...\n",
      "Finished recording.\n",
      "Prediction: down\n"
     ]
    }
   ],
   "source": [
    "# read audio and save it to a file\n",
    "def record_audio(): \n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=SAMPLE_RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=FRAMES_PER_BUFFER)\n",
    "\n",
    "    print(\"Recording audio...\")\n",
    "\n",
    "    frames = [] # A python-list of chunks(numpy.ndarray)\n",
    "\n",
    "    for i in range(0, int(SAMPLE_RATE / FRAMES_PER_BUFFER * DURATION)):\n",
    "        data = stream.read(FRAMES_PER_BUFFER)\n",
    "        frames.append(np.frombuffer(data, dtype=np.int16))\n",
    "\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    # stop and close stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    # save audio file\n",
    "    # convert the python-list of numpy-arrays into a 1D numpy-array\n",
    "    audio = np.hstack(frames)\n",
    "\n",
    "    # save as WAV file\n",
    "    filename = \"test.wav\"\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(SAMPLE_RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    return filename\n",
    "\n",
    "# preprocess and predict what class the command is\n",
    "def predict_command(model, filename):\n",
    "    # extract MFCCs\n",
    "    signal, sample_rate = librosa.load(filename, sr=SAMPLE_RATE)\n",
    "\n",
    "    # ensure consistency of the length of the signal\n",
    "    if len(signal) >= SAMPLE_RATE:\n",
    "        signal = signal[:SAMPLE_RATE]\n",
    "\n",
    "    # extract MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "    mfcc = mfcc.T\n",
    "\n",
    "    # reshape the 2d array to 1d array\n",
    "    mfcc = mfcc.reshape(mfcc.shape[0] * mfcc.shape[1])\n",
    "\n",
    "    # predict command\n",
    "    y_pred = model.predict([mfcc])\n",
    "    y_pred = y_pred[0]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# export prediction to arduino\n",
    "# def export_to_arduino(prediction):\n",
    "#     # connect to arduino\n",
    "#     ser = serial.Serial('COM3', 9600)\n",
    "#     time.sleep(2)\n",
    "\n",
    "#     # send prediction to arduino\n",
    "#     ser.write(bytes(prediction, 'utf-8'))\n",
    "\n",
    "#     # close connection\n",
    "#     ser.close()\n",
    "\n",
    "# Run the model\n",
    "if __name__ == \"__main__\":\n",
    "    # load the model\n",
    "    model = pickle.load(open(\"model.sav\", 'rb'))\n",
    "\n",
    "    # record the audio\n",
    "    filename = record_audio()\n",
    "\n",
    "    # predict the command\n",
    "    prediction = predict_command(model, filename)\n",
    "    print(\"Prediction: {}\".format(MAPPING[prediction]))\n",
    "    predic_string = MAPPING[prediction]\n",
    "\n",
    "    # send to arduino\n",
    "    # export_to_arduino(predic_string)\n",
    "\n",
    "    # remove the file\n",
    "    os.remove(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "581d25aded393500ae6bebc8eb996d976b34c560b26d9468ea6715d44ce9c365"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
